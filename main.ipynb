{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "import random\n",
    "from scipy.ndimage import rotate, zoom\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import gc\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "from keras import models, layers, losses, optimizers, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "def pickle_pi_set(pi, rng=range(359), plot=False, save=True):\n",
    "    if not os.path.exists(\"pickles\"):\n",
    "        os.mkdir(\"pickles\")\n",
    "\n",
    "    pi_set = []\n",
    "    mat_i = loadmat(f\"mats/data-science-P{pi+1}.mat\")\n",
    "    coord_to_col = mat_i[\"meta\"][0][0][8]\n",
    "    data = mat_i[\"data\"]\n",
    "    info = mat_i[\"info\"][0]\n",
    "\n",
    "    for i in tqdm(rng, desc=str(pi)):\n",
    "        datum = data[i][0][0]\n",
    "\n",
    "        scan = np.zeros((23, 61, 51))\n",
    "        for x in range(51):\n",
    "            for y in range(61):\n",
    "                for z in range(23):\n",
    "                    scan[z, y, x] = datum[coord_to_col[x, y, z] - 1]\n",
    "\n",
    "        mask = scan != mode(scan.flat).mode\n",
    "\n",
    "        masked_scan = scan[mask]\n",
    "        mask_mean, mask_std = np.mean(masked_scan), np.std(masked_scan)\n",
    "        lt_mask, gt_mask = masked_scan < mask_mean, masked_scan > mask_mean\n",
    "        std_left = np.sqrt(np.sum(np.square(masked_scan[lt_mask] - mask_mean)) / np.size(masked_scan[lt_mask]))\n",
    "        std_right = np.sqrt(np.sum(np.square(masked_scan[gt_mask] - mask_mean)) / np.size(masked_scan[gt_mask]))\n",
    "\n",
    "        scan[mask] -= mask_mean\n",
    "        scan[mask][scan[mask] < mask_mean] /= std_left\n",
    "        scan[mask][scan[mask] > mask_mean] /= std_right\n",
    "\n",
    "        n = 2.5\n",
    "        scan[scan > n * mask_std] = n * mask_std\n",
    "        scan[scan < -n * mask_std] = -n * mask_std\n",
    "        scan[scan == mode(scan.flat).mode] = scan[mask].min()\n",
    "\n",
    "        scan[scan < 0] /= abs(scan.min())\n",
    "        scan[scan > 0] /= scan.max()\n",
    "        \n",
    "        pi_set.append((scan, info[i][2][0]))\n",
    "\n",
    "    if save:\n",
    "        with open(f\"pickles/{pi}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(pi_set, f)\n",
    "    \n",
    "    \n",
    "\n",
    "    if plot:\n",
    "        scan = (scan - scan.min()) / (scan.max() - scan.min())\n",
    "\n",
    "        voxels = scan[scan != scan.min()]\n",
    "        indices = np.nonzero(scan)\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection=\"3d\")\n",
    "        ax.set_xticks([]) or ax.set_yticks([]) or ax.set_zticks([])\n",
    "\n",
    "        ax.scatter(indices[0], indices[1], indices[2], c=voxels, alpha=voxels, cmap=\"twilight\", s=30, marker=\"s\")\n",
    "        plt.show()\n",
    "\n",
    "        w = 5\n",
    "        fig, ax = plt.subplots(w, w, constrained_layout=True)\n",
    "        fig.dpi = 100\n",
    "        bg_color = (225 / 255, 216 / 255, 226 / 255)\n",
    "        fig.set_facecolor(bg_color)\n",
    "\n",
    "        for j in range(23):\n",
    "            ax[(j - j % w) // w, j % w].imshow(scan[j], vmin=0, vmax=1, cmap=\"twilight\")\n",
    "            ax[(j - j % w) // w, j % w].set_xticks([])\n",
    "            ax[(j - j % w) // w, j % w].set_yticks([])\n",
    "            plt.setp(ax[(j - j % w) // w, j % w].spines.values(), color=bg_color)\n",
    "\n",
    "        ax[4, 3].axis(\"off\") and ax[4, 4].axis(\"off\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_pi_set(0, range(359, 360), True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_set():\n",
    "    Pool(processes=5).map(pickle_pi_set, range(9))\n",
    "\n",
    "# pickle_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 60\n",
    "\n",
    "pickles = [pickle.load(open(f\"pickles/{i}.pkl\", \"rb\")) for i in range(5)]\n",
    "targets = set([pickles[0][i][1] for i in range(len(pickles[0]))])\n",
    "\n",
    "targets = list(targets)[:NUM_CLASSES]\n",
    "targets = {k: v for k, v in zip(targets, [[1 if i == j else 0 for i in range(NUM_CLASSES)] for j in range(len(targets))])}\n",
    "\n",
    "pickles = [item for sublist in pickles for item in sublist if item[1] in targets]\n",
    "print(len(pickles))\n",
    "\n",
    "split = int(0.8 * len(pickles))\n",
    "trains, tests = pickles[:split], pickles[split:]\n",
    "\n",
    "train_x = np.array([train[0] for train in trains])\n",
    "train_y = np.array([train[1] for train in trains])\n",
    "\n",
    "test_x = [test[0] for test in tests]\n",
    "test_y = [test[1] for test in tests]\n",
    "\n",
    "del pickles, trains, tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(i, train=True):\n",
    "    i = random.randint(0, len(train_x) - 1)\n",
    "\n",
    "    x, y = ((train_x, train_y) if train else (test_x, test_y))\n",
    "    scan, target = x[i], y[i]\n",
    "    \n",
    "    angles = np.random.randint(low=-5, high=5, size=(3, ))\n",
    "    scan = rotate(scan, angles[0], (0, 1))\n",
    "    scan = rotate(scan, angles[1], (1, 2))\n",
    "    scan = rotate(scan, angles[2], (2, 0))\n",
    "\n",
    "    scan = zoom(scan, [64 / s for s in scan.shape])\n",
    "    \n",
    "    scan = np.expand_dims(scan, -1)\n",
    "    target = targets[target]\n",
    "\n",
    "    return scan, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size=32, train=True):\n",
    "    \n",
    "    samples = list(Pool(processes=8).imap(get_sample, zip(range(batch_size), [train] * batch_size)))\n",
    "    batch_x = [sample[0] for sample in samples]\n",
    "    batch_y = [sample[1] for sample in samples]\n",
    "\n",
    "    return np.array(batch_x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = layers.Input((64, 64, 64, 1))\n",
    "    x = layers.Conv3D(8, 16, 1, activation=\"tanh\")(inputs)\n",
    "    x = layers.Conv3D(8, 8, 1, activation=\"tanh\")(x)\n",
    "    x = layers.Conv3D(8, 8, 1, activation=\"tanh\")(x)\n",
    "    x = layers.Conv3D(8, 8, 1, activation=\"tanh\")(x)\n",
    "    x = layers.Conv3D(8, 8, 1, activation=\"tanh\")(x)\n",
    "    x = layers.Conv3D(16, 8, 1, activation=\"tanh\")(x)\n",
    "    x = layers.Conv3D(32, 8, 1, activation=\"tanh\")(x)\n",
    "    x = layers.Conv3D(64, 4, 1, activation=\"tanh\")(x)\n",
    "    x = layers.Conv3D(128, 4, 1, activation=\"tanh\")(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "opt = optimizers.Adam()\n",
    "loss = losses.CategoricalCrossentropy()\n",
    "\n",
    "def train():\n",
    "    model.compile(opt, loss)\n",
    "\n",
    "    for i in range(1000):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            batch_x, batch_y = get_batch(32)\n",
    "            pred_y = model(batch_x)\n",
    "\n",
    "            batchloss = loss(batch_y, pred_y)\n",
    "            grad = tape.gradient(batchloss, model.trainable_variables)\n",
    "            opt.apply_gradients(zip(grad, model.trainable_variables))\n",
    "\n",
    "            print(i, float(batchloss))\n",
    "\n",
    "        if i % 100 == 0 and i != 0:\n",
    "            batch_x, batch_y = get_batch(512, train=True)\n",
    "            model.evaluate(batch_x, batch_y, batch_size=1)\n",
    "\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ephemerai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
