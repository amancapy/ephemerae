{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:03:31.890035: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-08 14:03:31.890114: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-08 14:03:31.890161: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "import random\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import models, layers, losses, optimizers, Model\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vectors():\n",
    "    with open(\"feature_vecs.txt\", \"r\") as f:\n",
    "        f = f.read().split(\"\\n\\n\\n\")\n",
    "        noun_dict = {}\n",
    "        for noun_vec in f:\n",
    "            split = noun_vec.split(\"\\n\\n\")\n",
    "            noun = split[0].split()[2][:-1]\n",
    "            \n",
    "            vec = split[1]\n",
    "            vec = [item.strip().replace(\"(\", \"\").replace(\")\", \"\") for item in vec.split(\",\\n\")]\n",
    "            vec = [(item.split()[:-1], item.split()[-1]) for item in vec]\n",
    "\n",
    "            vec = sorted(vec, key=lambda x: x[0])\n",
    "            vec = {\" \".join(item[0]): float(item[1]) for item in vec}\n",
    "\n",
    "            noun_dict[noun] = vec\n",
    "\n",
    "    return {k: [noun_dict[k][k1] for k1 in noun_dict[k]] for k in noun_dict}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 60\n",
    "\n",
    "pickles = [pickle.load(open(f\"pickles/{i}.pkl\", \"rb\")) for i in range(1)]\n",
    "pickles = [item for sublist in pickles for item in sublist]\n",
    "pickles = sorted(pickles, key=lambda x: x[1])\n",
    "\n",
    "feature_vectors = get_feature_vectors()\n",
    "\n",
    "nouns = list(set([item[1] for item in pickles]))\n",
    "\n",
    "pickles = [[item for item in pickles if item[1] == noun] for noun in nouns]\n",
    "pickles = [(np.add.reduce([item[0] for item in sublist]) / len(sublist), sublist[0][1]) for sublist in pickles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    x = (x - x.min()) / (x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scan(scan):\n",
    "    scan[scan == mode(scan.flat).mode] = -1\n",
    "    w = 5\n",
    "    fig, ax = plt.subplots(w, w, constrained_layout=True)\n",
    "    fig.dpi = 100\n",
    "    bg_color = (225 / 255, 216 / 255, 226 / 255)\n",
    "    fig.set_facecolor(bg_color)\n",
    "\n",
    "    for j in range(w * w):\n",
    "        ax[(j - j % w) // w, j % w].imshow(scan[j % scan.shape[0]], vmin=-1, vmax=1, cmap=\"twilight\")\n",
    "        ax[(j - j % w) // w, j % w].set_xticks([])\n",
    "        ax[(j - j % w) // w, j % w].set_yticks([])\n",
    "        plt.setp(ax[(j - j % w) // w, j % w].spines.values(), color=bg_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_plot(scan1, scan2):\n",
    "    scan1 = standardize(scan1)\n",
    "    scan2 = standardize(scan2)\n",
    "\n",
    "    scan1 = (scan1 - 0.5) * 2\n",
    "    scan2 = (scan2 - 0.5) * 2\n",
    "\n",
    "    scan1[scan1 == mode(scan1.flat).mode] = -1\n",
    "    scan2[scan2 == mode(scan2.flat).mode] = -1\n",
    "\n",
    "    w = 5\n",
    "    fig, ax = plt.subplots(w, 2 * w, constrained_layout=True)\n",
    "    fig.dpi = 100\n",
    "    bg_color = (225 / 255, 216 / 255, 226 / 255)\n",
    "    fig.set_facecolor(bg_color)\n",
    "\n",
    "    for j in range(w * w):\n",
    "        ax[(j - j % w) // w, j % w].imshow(scan1[j % scan1.shape[0]], vmin=-1, vmax=1, cmap=\"twilight\")\n",
    "        ax[(j - j % w) // w, j % w].set_xticks([])\n",
    "        ax[(j - j % w) // w, j % w].set_yticks([])\n",
    "        plt.setp(ax[(j - j % w) // w, j % w].spines.values(), color=bg_color)\n",
    "\n",
    "        ax[(j - j % w) // w, j % w + w].imshow(scan2[j % scan2.shape[0]], vmin=-1, vmax=1, cmap=\"twilight\")\n",
    "        ax[(j - j % w) // w, j % w + w].set_xticks([])\n",
    "        ax[(j - j % w) // w, j % w + w].set_yticks([])\n",
    "        plt.setp(ax[(j - j % w) // w, j % w + w].spines.values(), color=bg_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasisSum(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.basis = tf.Variable(tf.zeros((25, 23, 61, 51, 1)))\n",
    "\n",
    "    @tf.function(reduce_retracing=True)\n",
    "    def call(self, x):\n",
    "        x = tf.einsum(\"ijklm,bim->bjklm\", self.basis, x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "    return dot(a, b) / (norm(a) * norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.954: 100%|██████████| 500/500 [12:44<00:00,  1.53s/it]             \n"
     ]
    }
   ],
   "source": [
    "model = BasisSum()\n",
    "\n",
    "loss = losses.MeanSquaredError()\n",
    "opt = optimizers.Adam(0.01)\n",
    "\n",
    "total = 500\n",
    "pbar = tqdm(range(total))\n",
    "correct_count = 0\n",
    "\n",
    "for i in pbar:\n",
    "    random.shuffle(pickles)\n",
    "\n",
    "    x = np.array([item[1] for item in pickles])\n",
    "    x = [feature_vectors[item] for item in x]\n",
    "    x = np.array([item / np.linalg.norm(item) for item in x])\n",
    "    y = np.array([item[0] for item in pickles])\n",
    "    y_mean = np.add.reduce(y) / len(y)\n",
    "    y -= y_mean\n",
    "\n",
    "    x, y = np.expand_dims(x, -1), np.expand_dims(y, -1)\n",
    "    x, y = tf.cast(x, tf.dtypes.float32), tf.cast(y, tf.dtypes.float32)\n",
    "    \n",
    "    train_x, test_x = x[:-2], x[-2:]\n",
    "    train_y, test_y = y[:-2], y[-2:]\n",
    "\n",
    "    for j in range(100):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred_y = model(train_x)\n",
    "            batchloss = loss(train_y, pred_y)\n",
    "\n",
    "            grad = tape.gradient(batchloss, model.trainable_variables)\n",
    "            opt.apply_gradients(zip(grad, model.trainable_variables))\n",
    "\n",
    "\n",
    "    pred = model(test_x)\n",
    "    t1, t2 = test_y.numpy()\n",
    "    t1, t2 = t1.flat, t2.flat\n",
    "    p1, p2 = pred.numpy()\n",
    "    p1, p2 = p1.flat, p2.flat\n",
    "    \n",
    "    correct = cos_sim(t1, p1) + cos_sim(t2, p2) > cos_sim(t1, p2) + cos_sim(t2, p1)\n",
    "    correct_count += int(correct)\n",
    "\n",
    "    pbar.set_description(f\"accuracy: {correct_count / (i + 1):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ephemerai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
